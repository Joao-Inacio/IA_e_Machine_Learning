{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Processamento de Linguagem Natural Com Python**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marcação POS\n",
    "POS (part-of-speech) atribui para as palavras partes da fala, como substantivos, adjetivos, verbos\n",
    "Importante para a detecção de entidades no texto, pois primeiro é necessário saber o que o texto contém\n",
    "Lista de tokens: https://spacy.io/api/annotation#pos-tagging\n",
    "Português: https://www.sketchengine.eu/portuguese-freeling-part-of-speech-tagset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.pt.Portuguese at 0x289206fe510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando o spacy\n",
    "spacy.prefer_gpu()\n",
    "pln = spacy.load(\"pt_core_news_sm\")\n",
    "pln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o funcionamento\n",
    "doc = pln(\n",
    "        'Estou aprendendo processamento de linguagem natural, no curso Inteligência Artificial e Machine Learning: O Guia Completo'\n",
    ")\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou AUX\n",
      "aprendendo VERB\n",
      "processamento NOUN\n",
      "de ADP\n",
      "linguagem NOUN\n",
      "natural ADJ\n",
      ", PUNCT\n",
      "no ADP\n",
      "curso NOUN\n",
      "Inteligência PROPN\n",
      "Artificial PROPN\n",
      "e CCONJ\n",
      "Machine PROPN\n",
      "Learning PROPN\n",
      ": PUNCT\n",
      "O DET\n",
      "Guia PROPN\n",
      "Completo PROPN\n"
     ]
    }
   ],
   "source": [
    "# Iterando os tipos \n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematização e stemização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou estar\n",
      "aprendendo aprender\n",
      "processamento processamento\n",
      "de de\n",
      "linguagem linguagem\n",
      "natural natural\n",
      ", ,\n",
      "no em o\n",
      "curso curso\n",
      "Inteligência Inteligência\n",
      "Artificial Artificial\n",
      "e e\n",
      "Machine Machine\n",
      "Learning Learning\n",
      ": :\n",
      "O o\n",
      "Guia Guia\n",
      "Completo Completo\n"
     ]
    }
   ],
   "source": [
    "# texto e lema\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\joaoi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baixando o arquivo necessário para a stemização\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aprend'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraído o radical de uma palavra\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "stemmer.stem('aprendendo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou estar est\n",
      "aprendendo aprender aprend\n",
      "processamento processamento process\n",
      "de de de\n",
      "linguagem linguagem lingu\n",
      "natural natural natur\n",
      ", , ,\n",
      "no em o no\n",
      "curso curso curs\n",
      "Inteligência Inteligência intelig\n",
      "Artificial Artificial artific\n",
      "e e e\n",
      "Machine Machine machin\n",
      "Learning Learning learning\n",
      ": : :\n",
      "O o o\n",
      "Guia Guia gui\n",
      "Completo Completo complet\n"
     ]
    }
   ],
   "source": [
    "# Verificando a diferença \n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, stemmer.stem(token.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
